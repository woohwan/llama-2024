{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare your Instruction Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-04-17 16:45:52--  https://raw.githubusercontent.com/Instruction-Tuning-with-GPT-4/GPT-4-LLM/main/data/alpaca_gpt4_data.json\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 43379276 (41M) [text/plain]\n",
      "Saving to: ‘alpaca_gpt4_data.json’\n",
      "\n",
      "alpaca_gpt4_data.js 100%[===================>]  41.37M  8.15MB/s    in 5.0s    \n",
      "\n",
      "2024-04-17 16:46:00 (8.28 MB/s) - ‘alpaca_gpt4_data.json’ saved [43379276/43379276]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# !wget https://raw.githubusercontent.com/Instruction-Tuning-with-GPT-4/GPT-4-LLM/main/data/alpaca_gpt4_data.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "dataset_file = \"alpaca_gpt4_data.json\"\n",
    "\n",
    "with open(dataset_file, \"r\") as f:\n",
    "    alpaca = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list,\n",
       " [{'instruction': 'Give three tips for staying healthy.',\n",
       "   'input': '',\n",
       "   'output': '1. Eat a balanced and nutritious diet: Make sure your meals are inclusive of a variety of fruits and vegetables, lean protein, whole grains, and healthy fats. This helps to provide your body with the essential nutrients to function at its best and can help prevent chronic diseases.\\n\\n2. Engage in regular physical activity: Exercise is crucial for maintaining strong bones, muscles, and cardiovascular health. Aim for at least 150 minutes of moderate aerobic exercise or 75 minutes of vigorous exercise each week.\\n\\n3. Get enough sleep: Getting enough quality sleep is crucial for physical and mental well-being. It helps to regulate mood, improve cognitive function, and supports healthy growth and immune function. Aim for 7-9 hours of sleep each night.'},\n",
       "  {'instruction': 'What are the three primary colors?',\n",
       "   'input': '',\n",
       "   'output': 'The three primary colors are red, blue, and yellow. These colors are called primary because they cannot be created by mixing other colors and all other colors can be made by combining them in various proportions. In the additive color system, used for light, the primary colors are red, green, and blue (RGB).'},\n",
       "  {'instruction': 'Describe the structure of an atom.',\n",
       "   'input': '',\n",
       "   'output': \"An atom is the basic building block of all matter and is made up of three types of particles: protons, neutrons, and electrons. The structure of an atom can be described as a nucleus at the center surrounded by a cloud of electrons.\\n\\nThe nucleus of an atom is made up of protons and neutrons. Protons are positively charged particles and neutrons are neutral particles with no charge. Both of these particles are located in the nucleus of the atom, which is at the center of the atom and contains most of the atom's mass.\\n\\nSurrounding the nucleus of the atom is a cloud of electrons. Electrons are negatively charged particles that are in constant motion around the nucleus. The electron cloud is divided into shells or orbitals, and each shell can hold a certain number of electrons. The number of electrons in the outermost shell, called the valence shell, determines the chemical properties of the atom. \\n\\nIn a neutral atom, the number of protons in the nucleus is equal to the number of electrons in the electron cloud, so the positive and negative charges balance out and the atom has no overall charge. The number of protons, also called the atomic number, determines what element the atom is.\"}],\n",
       " 52002)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(alpaca), alpaca[:3], len(alpaca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the dataset has instruction and outputs. The model is trained to predict the next token, so one option would be just to concat both, and train on that. We ideally format the prompt in a way that we make explicit where is the input and output. Let's log the dataset to W&B so we keep everything organised"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log The Alpaca Dataset to W&B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/whpark/temp/ft/wandb/run-20240417_165034-qhb38ayi</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/whpark70/alpaca_ft/runs/qhb38ayi' target=\"_blank\">azure-pine-8</a></strong> to <a href='https://wandb.ai/whpark70/alpaca_ft' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/whpark70/alpaca_ft' target=\"_blank\">https://wandb.ai/whpark70/alpaca_ft</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/whpark70/alpaca_ft/runs/qhb38ayi' target=\"_blank\">https://wandb.ai/whpark70/alpaca_ft/runs/qhb38ayi</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50f3c13e6cec43b98189f6324937ecf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='45.978 MB of 45.978 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">azure-pine-8</strong> at: <a href='https://wandb.ai/whpark70/alpaca_ft/runs/qhb38ayi' target=\"_blank\">https://wandb.ai/whpark70/alpaca_ft/runs/qhb38ayi</a><br/> View project at: <a href='https://wandb.ai/whpark70/alpaca_ft' target=\"_blank\">https://wandb.ai/whpark70/alpaca_ft</a><br/>Synced 5 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240417_165034-qhb38ayi/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import wandb\n",
    "import os\n",
    "\n",
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"/home/whpark/temp/ft/alpaca-gpt4.ipynb\"\n",
    "\n",
    "# log to wandb\n",
    "with wandb.init(project=\"alpaca_ft\"):\n",
    "    at = wandb.Artifact(\n",
    "        name=\"alpaca_gpt4\", \n",
    "        type=\"dataset\",\n",
    "        description=\"A GPT4 generated Alpaca like dataset for instruction finetunning\",\n",
    "        metadata={\"url\":\"https://github.com/Instruction-Tuning-with-GPT-4/GPT-4-LLM#how-good-is-the-data\"},\n",
    "    )\n",
    "    at.add_file(dataset_file)\n",
    "\n",
    "    # log as a table\n",
    "    table = wandb.Table(columns=list(alpaca[0].keys()))\n",
    "    for row in alpaca:\n",
    "        table.add_data(*row.values())\n",
    "    wandb.log({\"alpaca_gpt4_table\": table})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Eval Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "seed=42\n",
    "\n",
    "random.seed(seed)\n",
    "random.shuffle(alpaca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = alpaca[:-1000]\n",
    "eval_dataset = alpaca[-1000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we should save the split to W&B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/whpark/temp/ft/wandb/run-20240417_173600-ilp9ycat</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/whpark70/alpaca_ft/runs/ilp9ycat' target=\"_blank\">skilled-plasma-9</a></strong> to <a href='https://wandb.ai/whpark70/alpaca_ft' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/whpark70/alpaca_ft' target=\"_blank\">https://wandb.ai/whpark70/alpaca_ft</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/whpark70/alpaca_ft/runs/ilp9ycat' target=\"_blank\">https://wandb.ai/whpark70/alpaca_ft/runs/ilp9ycat</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f05a5eb2d61b4a4093862dba7e7628b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='87.209 MB of 87.209 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">skilled-plasma-9</strong> at: <a href='https://wandb.ai/whpark70/alpaca_ft/runs/ilp9ycat' target=\"_blank\">https://wandb.ai/whpark70/alpaca_ft/runs/ilp9ycat</a><br/> View project at: <a href='https://wandb.ai/whpark70/alpaca_ft' target=\"_blank\">https://wandb.ai/whpark70/alpaca_ft</a><br/>Synced 5 W&B file(s), 2 media file(s), 4 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240417_173600-ilp9ycat/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.DataFrame(train_dataset)\n",
    "eval_df = pd.DataFrame(eval_dataset)\n",
    "\n",
    "train_table = wandb.Table(dataframe=train_df)\n",
    "eval_table = wandb.Table(dataframe=eval_df)\n",
    "\n",
    "train_df.to_json(\"alpaca_gpt4_train.jsonl\", orient='records', lines=True)\n",
    "eval_df.to_json(\"alpaca_gpt4_eval.jsonl\", orient='records', lines=True)\n",
    "\n",
    "with wandb.init(project=\"alpaca_ft\", job_type='split_data'):\n",
    "    at = wandb.Artifact(\n",
    "        name=\"alpaca_gpt4_splitted\",\n",
    "        type=\"dataset\",\n",
    "        description=\"A GPT4 generated Alpaca like dataset for instruction finetunning\",\n",
    "        metadata={\"url\":\"https://github.com/Instruction-Tuning-with-GPT-4/GPT-4-LLM#how-good-is-the-data\"},\n",
    "    )\n",
    "    at.add_file(\"alpaca_gpt4_train.jsonl\")\n",
    "    at.add_file(\"alpaca_gpt4_eval.jsonl\")\n",
    "    wandb.log_artifact(at)\n",
    "    wandb.log({\"train_dataset\": train_table, \"eval_dataset\": eval_table})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
